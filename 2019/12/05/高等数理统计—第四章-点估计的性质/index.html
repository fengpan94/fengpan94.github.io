<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="欢迎指正。">
<meta property="og:type" content="article">
<meta property="og:title" content="高等数理统计—第四章 点估计的性质">
<meta property="og:url" content="http://www.fengpan.xyz/2019/12/05/高等数理统计—第四章-点估计的性质/index.html">
<meta property="og:site_name" content="风磐&#39;Blog">
<meta property="og:description" content="欢迎指正。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-11-21T12:41:15.405Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="高等数理统计—第四章 点估计的性质">
<meta name="twitter:description" content="欢迎指正。">
  <link rel="canonical" href="http://www.fengpan.xyz/2019/12/05/高等数理统计—第四章-点估计的性质/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>高等数理统计—第四章 点估计的性质 | 风磐'Blog</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">风磐'Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">谁无暴风劲雨时 守得云开见月明</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
  </ul>

    

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://www.fengpan.xyz/2019/12/05/高等数理统计—第四章-点估计的性质/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Feng Pan">
      <meta itemprop="description" content="高等数理统计、高等概率论学习心得">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风磐'Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">高等数理统计—第四章 点估计的性质

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-12-05 16:21:13" itemprop="dateCreated datePublished" datetime="2019-12-05T16:21:13+08:00">2019-12-05</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-11-21 20:41:15" itemprop="dateModified" datetime="2019-11-21T20:41:15+08:00">2019-11-21</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>欢迎指正。</p><a id="more"></a>
<h1 id="第四章-点估计的性质-有效性、渐近性"><a href="#第四章-点估计的性质-有效性、渐近性" class="headerlink" title="第四章 点估计的性质(有效性、渐近性)"></a>第四章 点估计的性质(有效性、渐近性)</h1><p>上一章介绍了几种点估计方法以及两个关键的优良性准则：无偏性和最小风险(特例：最小均方误差)。本章我们将介绍与估计量的均方误差有密切关系的有效性问题。因为大多数情况下估计量的最小均方误差都不可能无限指的小，而是有一个<strong>C-R下界</strong>，因此达到这个下界的估计量最好，称为<strong>‘最有效’</strong>。</p>
<p>本章的第二个重点内容就是估计量的<strong>渐进性质</strong>，像相合性、渐进正态性、收敛性。</p>
<h2 id="4-1-C-R不等式"><a href="#4-1-C-R不等式" class="headerlink" title="4.1 C-R不等式"></a>4.1 C-R不等式</h2><p>我们先来看以下均方误差的推导吧，顺便回顾一下上一节的无偏性与风险函数：首先损失函数$L(\theta,d)$为凸函数，风险函数为损失函数的期望$R(\theta,\hat{g})=E_\theta[L(\theta,\hat{g}(X))]$，如果损失函数$L(\theta,d)=(d-g(\theta))^2$，风险函数即为<strong>均方误差(MSE)</strong>，此时有：</p>
<script type="math/tex; mode=display">
\begin{align}
R(\theta,\hat{g})=MSE(\hat{g}(X))&=E_\theta[L(\theta,\hat{g}(X))]\\
&=E_\theta[\hat{g}(X)-g(\theta)]^2\\
&=E_\theta[\hat{g}(X)-E\hat{g}(X)+E\hat{g}(X)-g(\theta)]~*加一项减一项是个常用的技巧\\
&=E_\theta[\hat{g}(X)-E\hat{g}(X)]+[E\hat{g}(X)-g(\theta)]^2\\
&=Var_\theta(\hat{g}(X))+[bias(\hat{g}(X))]^2
\end{align}</script><p>由此可以看出，估计量的<strong>均方误差=方差+偏差</strong>$^2$。对于无偏估计来说，由于$bias(\hat{g}(X))=0$，所以有$MSE(\hat{g}(X))=Var_\theta(\hat{g}(X))$，因此<strong>要求估计量的均方误差尽可能的小，等价于要求估计量的方差尽可能小。</strong></p>
<hr>
<p>补充一下正则分布族（C-R分布族）的定义，可能会用到，大部分情况下我们见到的分布族都满足正则分布族的定义，<strong>常见的分布只有均匀分布和带位置参数的指数分布(也没那么常见)不是正则分布族</strong>。</p>
<p>正则分布族需要满足的几个基本条件摘要如下：</p>
<p>（1）$\{f(x,\theta),\theta\in\Theta\}$有共同支撑，即$S_\theta=\{x:f(x,\theta)&gt;0\}$与$\theta$无关</p>
<p>（2）$L(\theta)=L(\theta,x)=\log f(x,\theta)$关于$\theta$连续、可导；$S_i(X,\theta)=\frac{\partial}{\partial\theta_i}L(\theta)$存在二阶矩，且有$E_\theta[S_i(X,\theta)]=0,E_\theta[S_i(X,\theta)S_j(X,\theta)]=I_{ij}(\theta),I(\theta)=(I_{ij}(\theta))$为Fisher信息阵。</p>
<p>（3）$f(x,\theta)$关于$\theta$求导与关于x求积分可交换次序</p>
<hr>
<h3 id="4-1-1-分布参数为一维的情况"><a href="#4-1-1-分布参数为一维的情况" class="headerlink" title="4.1.1 分布参数为一维的情况"></a>4.1.1 分布参数为一维的情况</h3><p>我们省去太多有关C-R不等式及证明的内容，上干货：</p>
<p><strong>C-R不等式</strong>：</p>
<script type="math/tex; mode=display">
~Var[\hat{g}(X)]\ge\frac{[g'(\theta)]^2}{I(\theta)}</script><p>C-R不等式说明，在C-R分布族中，$g(\theta)$的任何无偏估计$\hat{g}(\theta)$，不管形式如何，其方差，即均方误差总是有下界的，其<strong>方差下界（CRLB）</strong>为$[g’(\theta)]^2\cdot I^{-1}(\theta)$，与估计量无关，因此方差能达到下界的无偏估计必然是最优的。</p>
<blockquote>
<p>其中$I(\theta)$是Fisher信息量，我们在<strong>第二章的2.4节—分布族的信息函数</strong>给过详细的介绍，计算公式为$I(\theta)=-E_\theta\left(\frac{d^2}{d\theta^2}\ln f(X;\theta)\right)$</p>
</blockquote>
<p>根据以上分析提出以下有效性的定义：</p>
<p><strong>定义1</strong> 设$\hat{g}(\theta)$为$g(\theta)$的无偏估计，若其方差达到C-R下界，即</p>
<script type="math/tex; mode=display">
Var[\hat{g}(X)]=[g'(\theta)]^2\cdot I^{-1}(\theta) \tag{1}</script><p>则称$\hat{g}(X)$为$g(\theta)$的<strong>有效无偏估计</strong>。</p>
<p><strong>例1</strong>  设$X_1,…,X_n$独立同分布，$X_1\sim P(\lambda)$（Poisson分布），计算$\lambda,e^{-\lambda}$的无偏估计的C-R下界</p>
<p>（1）取$g(\lambda)=\lambda$，这时$\hat{\lambda}=\overline{X}$为一致最小方差无偏估计，且有$Var(\hat{\lambda})=\lambda/n$，且我们容易求得$I(\lambda)=n/\lambda$，因此有$CRLB=1\cdot I^{-1}(\lambda)=\lambda/n$.</p>
<blockquote>
<p>无偏估计、方差、信息函数的计算细节就不给出了，我们主要是给出C-R下界的计算流程。</p>
<p>这里我们可以看到$CRLB=Var(\hat{\lambda})$，所以$\hat{\lambda}=\overline{X}$为有效无偏估计。</p>
</blockquote>
<p>（2）取$g(\lambda)=e^{-\lambda}$，这时$\hat{g}(X)=(1-\frac{1}{n})^T$为$e^{-\lambda}$一致最小方差无偏估计，其中$T=\sum X_i$，且有$Var[\hat{g}(X)]=e^{-2\lambda}(e^{\frac{\lambda}{n}}-1)$，还有$I(\lambda)=n/\lambda$，因此有$CRLB=[g’(\theta)]^2\cdot I^{-1}(\theta)=e^{-2\lambda}\frac{\lambda}{n}$.</p>
<blockquote>
<p>这里可以看出，$CRLB&lt;Var[\hat{g}(X)]$，因此$\hat{g}(X)=(1-\frac{1}{n})^T$不是$e^{-\lambda}$的有效无偏估计。</p>
</blockquote>
<p><strong>定义2</strong> 若$\hat{g}(X)$为$g(\theta)$的无偏估计，且有</p>
<script type="math/tex; mode=display">
e(\hat{g})=\frac{CRLB}{Var[\hat{g}(X)]}\rightarrow1(n\rightarrow+\infty)</script><p>则称$\hat{g}(X)$为<strong>渐进有效无偏估计</strong>。$e(\hat{g})$称为估计量$\hat{g}(X)$的效率(efficiency)，有的书上也叫效。</p>
<p><strong>例2</strong> 以例1的第二问为例，尽管$\hat{g}(X)=(1-\frac{1}{n})^T$不是$e^{-\lambda}$的有效无偏估计，但是当$n\rightarrow\infty$时，有$\frac{CRLB}{Var[\hat{g}(X)]}=\frac{\lambda/n}{e^{\frac{\lambda}{n}}-1}\rightarrow1$，因此$\hat{g}(X)=(1-\frac{1}{n})^T$是$e^{-\lambda}$的渐进有效无偏估计。</p>
<h3 id="4-1-2-等式成立的情况"><a href="#4-1-2-等式成立的情况" class="headerlink" title="4.1.2 等式成立的情况"></a>4.1.2 等式成立的情况</h3><p>C-R不等式为我们提供了方差下界，大部分情况下估计量的方差是大于C-R下界的，等于CRLB的无偏估计我们就称之为有效无偏估计。那么什么时候等于？就是我们在这一小节要说的。</p>
<p><strong>定理1</strong> （简单说）设$\{f(x,\theta),\theta\in\Theta\}$为C-R分布族，无偏估计$\hat{g}(X)$为$g(\theta)$的有效无偏估计的充要条件是$f(x,\theta)$服从指数族分布：$f(x,\theta)=h(x)\exp\{Q(\theta)\hat{g}(x)-b(\theta)\}$</p>
<p>over</p>
<h3 id="4-1-3-分布参数为多维的情况"><a href="#4-1-3-分布参数为多维的情况" class="headerlink" title="4.1.3 分布参数为多维的情况"></a>4.1.3 分布参数为多维的情况</h3><p><strong>定理2</strong> 设$X\sim\{f(x,\theta),\theta\in\Theta\}$为$C-R$分布族，$\hat{g}(X)$为$g(\theta)$的无偏估计，则有</p>
<script type="math/tex; mode=display">
Var_\theta[\hat{g}(X)]\ge G'(\theta)I^{-1}(\theta)G(\theta)=\left(\frac{\partial}{\partial\theta}g(\theta)\right)'I^{-1}(\theta)\left(\frac{\partial}{\partial\theta}g(\theta)\right)</script><p>如同一维参数的情况，若上式等号成立，就称估计量$\hat{g}(X)$为无偏有效估计量。</p>
<p><strong>例3</strong>  设$X_1,…,X_n$为来自正态分布$N(\mu,\sigma^2)$的简单样本，$\theta=(\mu,\sigma^2)$，与第二章内容的不同点在于我们这里是n个样本，因此$X=(X_1,…,X_n)$的密度函数为</p>
<script type="math/tex; mode=display">
f(x,\theta)=(2\pi\sigma^2)^{-\frac{n}{2}}\exp\{-\frac{1}{2\sigma^2}\sum^n_{i=1}(x_i-\mu)^2\}</script><p>计算Fisher信息有：</p>
<script type="math/tex; mode=display">
\ln f(x,\theta)=-\frac{n}{2}\ln(2\pi\sigma^2)-\frac{1}{2\sigma^2}\sum^n_{i=1}(x_i-\mu)^2\\
\frac{\partial\ln f(x,\theta)}{\partial\mu}=\frac{1}{\sigma^2}\sum^n_{i=1}(x_i-\mu)\\
\frac{\partial^2\ln f(x,\theta)}{\partial\mu^2}=-\frac{n}{\sigma^2}\\
\frac{\partial\ln f(x,\theta)}{\partial(\sigma^2)}=-\frac{n}{2\sigma^2}+\frac{\sum^n_{i=1}(x_i-\mu)^2}{2\sigma^4}\\
\frac{\partial^2\ln f(x,\theta)}{\partial(\sigma^2)^2}=\frac{n}{2\sigma^4}-\frac{\sum^n_{i=1}(x_i-\mu)^2}{\sigma^6}\\
\frac{\partial^2\ln f(x,\theta)}{\partial\mu\partial(\sigma^2)}=-\frac{\sum^n_{i=1}(x_i-\mu)}{\sigma^4}</script><p>求期望我们可得Fisher信息矩阵：</p>
<script type="math/tex; mode=display">
I(\mu,\sigma^2)=\begin{pmatrix}
\frac{n}{\sigma^2} & 0 \\
0 & \frac{n}{2\sigma^4}
\end{pmatrix}</script><p>现有两个待估参数$g_1(\theta)=\mu,g_2(\theta)=\sigma^2$</p>
<p>参数$g_1(\theta)=\mu$的无偏估计方差的CRLB为</p>
<script type="math/tex; mode=display">
\begin{align}
\left(\frac{\partial}{\partial\theta}g_1(\theta)\right)'I^{-1}(\theta)\left(\frac{\partial}{\partial\theta}g_1(\theta)\right)
&=(1,0)\begin{pmatrix}
\frac{n}{\sigma^2} & 0 \\
0 & \frac{n}{2\sigma^4}\end{pmatrix}^{-1}\binom{1}{0}\\
&=(1,0)\begin{pmatrix}
\frac{\sigma^2}{n} & 0 \\
0 & \frac{2\sigma^4}{n}\end{pmatrix}^{-1}\binom{1}{0}\\
&=\frac{\sigma^2}{n}
\end{align}</script><p>参数$g_2(\theta)=\sigma^2$的无偏估计方差的CRLB为</p>
<script type="math/tex; mode=display">
\begin{align}
\left(\frac{\partial}{\partial\theta}g_2(\theta)\right)'I^{-1}(\theta)\left(\frac{\partial}{\partial\theta}g_2(\theta)\right)
&=(0,1)\begin{pmatrix}
\frac{n}{\sigma^2} & 0 \\
0 & \frac{n}{2\sigma^4}\end{pmatrix}^{-1}\binom{0}{1}\\
&=(0,1)\begin{pmatrix}
\frac{\sigma^2}{n} & 0 \\
0 & \frac{2\sigma^4}{n}\end{pmatrix}^{-1}\binom{0}{1}\\
&=\frac{2\sigma^4}{n}
\end{align}</script><p>已知$g_1(\theta)=\mu$的无偏估计——样本均值$\overline{X}$的方差$\frac{\sigma^2}{n}=RCLB$，因此样本均值$\overline{X}$是$\mu$的有效无偏估计。已知$g_2(\theta)=\sigma^2$的无偏估计——样本方差$S^2$，依据$Y=\frac{n-1}{\sigma^2}S^2\sim\chi^2(n-1)$，可以计算$Var(S^2)=Var(\frac{\sigma^2}{n-1}Y)=(\frac{\sigma^2}{n-1})^2Var(Y)=(\frac{\sigma^2}{n-1})^2\cdot2(n-1)=\frac{2\sigma^4}{n-1}&gt;RCLB=\frac{2\sigma^4}{n}$，因此样本方差$S^2$不是$\sigma^2$的有效无偏估计。</p>
<h2 id="4-2-估计量的渐进性质"><a href="#4-2-估计量的渐进性质" class="headerlink" title="4.2 估计量的渐进性质"></a>4.2 估计量的渐进性质</h2><h3 id="4-2-1-随机变量序列的收敛性"><a href="#4-2-1-随机变量序列的收敛性" class="headerlink" title="4.2.1 随机变量序列的收敛性"></a>4.2.1 随机变量序列的收敛性</h3><p>关于随机变量序列的收敛性我们在概率论中也将会讲到，可以看看那边，相互印证。</p>
<hr>
<p>记$\xi_n,\xi,\eta$为随机变量，$b,c$为常；$\xi_n\sim F_n(x),\xi\sim F(x)$为分布函数。当$n\rightarrow+\infty$时，随机变量的收敛性通常有以下几种：</p>
<p><strong>依概率收敛</strong>，$\xi_n\ \stackrel{P}{\rightarrow}\xi$：若$P(|\xi_n-\xi|\ge\epsilon)\rightarrow0(n\rightarrow+\infty),\forall\epsilon&gt;0$.</p>
<p><strong>r阶矩收敛</strong>，$\xi_n\ \stackrel{r}{\rightarrow}\xi$：若$E|\xi_n-\xi|^r\rightarrow0(n\rightarrow+\infty)$；特别当$r=2$时，记为$MSE(\xi_n)\rightarrow0$.</p>
<p><strong>几乎处处收敛</strong>，$\xi_n\rightarrow\xi(a.e.)or(a.s.)$：若$P\{x:\lim_{n\rightarrow+\infty}\xi_n(x)=\xi(x)\}=1$，即对$P(A)=1$，当$x\in A$时有$\xi_n(x)\rightarrow\xi(x)(n\rightarrow+\infty)$；这也可表示为$P\{\xi_n\rightarrow\xi(n\rightarrow+\infty)\}=1$.</p>
<p><strong>依分布收敛</strong>，$\xi_n\stackrel{L}{\rightarrow}\xi$或$\xi_n\stackrel{d}{\rightarrow}\xi$：若在$F(x)$的连续点处有$F_n(x)\rightarrow F(x)(n\rightarrow+\infty)$.</p>
<blockquote>
<p>常用性质：$\xi_n\rightarrow\xi(a.e.)\Longrightarrow\xi_n\stackrel{P}{\rightarrow}\xi\Longrightarrow\xi_n\stackrel{L}{\rightarrow}\xi$</p>
</blockquote>
<hr>
<p>下定理对于推导随机序列的渐进分布十分有用：</p>
<p><strong>定理1（Slutsky）</strong>当$n\rightarrow+\infty$时，若$\xi_n\stackrel{L}{\rightarrow}\xi,\eta_n\stackrel{P}{\rightarrow}c$，则有：</p>
<script type="math/tex; mode=display">
\xi_n+\eta_n\stackrel{L}{\rightarrow}\xi+c,~~\xi_n\eta_n\stackrel{L}{\rightarrow}c\xi,~~\eta^{-1}_n\xi_n\stackrel{L}{\rightarrow}c^{-1}\xi(c\not=0)</script><p>特别，若$\eta_n\stackrel{P}{\rightarrow}0$，则$\xi_n+\eta_n\stackrel{L}{\rightarrow}\xi$（去0率）；若$\eta_n\stackrel{P}{\rightarrow}1$，则$\xi_n\eta_n\stackrel{L}{\rightarrow}\xi$（去1率）</p>
<p><strong>例1</strong> t分布的渐近正态性。设$X_1,…,X_n$独立同分布，$X_1\sim N(0,\sigma^2)$，则当$n\rightarrow+\infty$时有$t_n\stackrel{L}{\rightarrow}N(0,1)$，其中</p>
<script type="math/tex; mode=display">
t_n=\frac{\sqrt{n}\overline{X}}{\sqrt{\sum^n_{i=1}(X_i-\overline{X})^2/(n-1)}}</script><p>证明：首先有$\overline{X}\sim N(0,\sigma^2/n)\Longrightarrow\sqrt{n}\overline{X}/\sigma\sim N(0,1),~S^2=n^{-1}\sum(X_i-\overline{X})^2\stackrel{P}{\rightarrow}\sigma^2$（见例2），因此$t_n=\frac{\sqrt{n}\overline{X}}{\sigma}\frac{\sigma}{S}\sqrt{\frac{n-1}{n}}$（构造出题目中$t_n$的形式），依据Slutsky定理“去1律”，因为$\frac{\sigma}{S}\rightarrow1,\frac{n-1}{n}\rightarrow1$，所以$t_n\stackrel{L}{\rightarrow}N(0,1)$.</p>
<h3 id="4-2-2-估计量的相合性和渐近正态性"><a href="#4-2-2-估计量的相合性和渐近正态性" class="headerlink" title="4.2.2 估计量的相合性和渐近正态性"></a>4.2.2 估计量的相合性和渐近正态性</h3><p><strong>定义1</strong> 当$n\rightarrow+\infty$时，若对一切$\theta\in\Theta$有$\hat{g}(X_1,…,X_n)\stackrel{P_\theta}{\rightarrow}g(\theta)$，则称$\hat{g}(X_1,…,X_n)$为$g(\theta)$的<strong>相合估计（或弱相合估计）</strong>。若$\hat{g}(X_1,…,X_n)\rightarrow g(\theta)(a.e.P_\theta,\theta\in\Theta)$，则称$\hat{g}(X_1,…,X_n)$为$g(\theta)$的<strong>强相合估计</strong>。 </p>
<hr>
<p><strong>定义2</strong> 若存在$\nu(\theta)&gt;0$使$Z_n=\sqrt{n}\{\hat{g}(X_1,…,X_n)-g(\theta)\}\stackrel{L}{\rightarrow}Z\sim N(0,\nu(\theta))$，则称$\hat{g}_n(X)$为<strong>渐近正态</strong>的，也称$\hat{g}_n(X)$为$g(\theta)$的<strong>相合渐进正态（CAN）估计</strong>。</p>
<h3 id="4-2-3-矩估计的相合性和渐近正态性"><a href="#4-2-3-矩估计的相合性和渐近正态性" class="headerlink" title="4.2.3 矩估计的相合性和渐近正态性"></a>4.2.3 矩估计的相合性和渐近正态性</h3><h3 id="4-2-4-极大似然估计的相合性和渐近正态性"><a href="#4-2-4-极大似然估计的相合性和渐近正态性" class="headerlink" title="4.2.4 极大似然估计的相合性和渐近正态性"></a>4.2.4 极大似然估计的相合性和渐近正态性</h3>
    </div>

    
    
    
        
      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/12/05/高等数理统计—第三章-点估计/" rel="next" title="高等数理统计—第三章 点估计">
                  <i class="fa fa-chevron-left"></i> 高等数理统计—第三章 点估计
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/12/05/高等数理统计—第五章-参数假设检验/" rel="prev" title="高等数理统计—第五章 参数假设检验">
                  高等数理统计—第五章 参数假设检验 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#第四章-点估计的性质-有效性、渐近性"><span class="nav-number">1.</span> <span class="nav-text">第四章 点估计的性质(有效性、渐近性)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-C-R不等式"><span class="nav-number">1.1.</span> <span class="nav-text">4.1 C-R不等式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-1-分布参数为一维的情况"><span class="nav-number">1.1.1.</span> <span class="nav-text">4.1.1 分布参数为一维的情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-2-等式成立的情况"><span class="nav-number">1.1.2.</span> <span class="nav-text">4.1.2 等式成立的情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-3-分布参数为多维的情况"><span class="nav-number">1.1.3.</span> <span class="nav-text">4.1.3 分布参数为多维的情况</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-估计量的渐进性质"><span class="nav-number">1.2.</span> <span class="nav-text">4.2 估计量的渐进性质</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-随机变量序列的收敛性"><span class="nav-number">1.2.1.</span> <span class="nav-text">4.2.1 随机变量序列的收敛性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-估计量的相合性和渐近正态性"><span class="nav-number">1.2.2.</span> <span class="nav-text">4.2.2 估计量的相合性和渐近正态性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-3-矩估计的相合性和渐近正态性"><span class="nav-number">1.2.3.</span> <span class="nav-text">4.2.3 矩估计的相合性和渐近正态性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-4-极大似然估计的相合性和渐近正态性"><span class="nav-number">1.2.4.</span> <span class="nav-text">4.2.4 极大似然估计的相合性和渐近正态性</span></a></li></ol></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Feng Pan</p>
  <div class="site-description" itemprop="description">高等数理统计、高等概率论学习心得</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">9</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
  </nav>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Feng Pan</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.4.0</div>

        












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/muse.js?v=7.4.0"></script>
<script src="/js/next-boot.js?v=7.4.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

</body>
</html>
